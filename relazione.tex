\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{braket}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}

\title{Crittografia Post-Quantum}
\author{Olivieri Michele}
\date{\today}

\begin{document}

\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduzione}

\subsection{Contesto e motivazioni} 

Per comprendere l'importanza della crittografia post-quantistica, è fondamentale analizzare 
il contesto in cui essa si inserisce e le motivazioni che ne hanno guidato lo sviluppo.

La crittografia classica, come visto a lezione, pone le sue fondamenta su problemi computazionalmente difficili 
per i quali non esistono algoritmi efficienti in grado di risolverli in tempi polinomiali.

Tuttavia, l'emergere dei computer quantistici ha introdotto una nuova dimensione nel panorama della sicurezza informatica.
Questi dispositivi sfruttando i principi della meccanica quantistica sono in grado di eseguire calcoli in modo radicalmente diverso 
rispetto ai computer classici, rendendoli potenzialmente capaci di risolvere in tempi polinomiali quei problemi matematici 
che risultano intrattabili per le macchine convenzionali\footnote{\href{https://archive.org/details/QuantumComputationAndQuantumInformation10thAnniversaryEdition}{Nielsen \& Chuang, Sezione 1.1}}.

\subsection[Minaccia dei computer quantistici]{Minaccia dei computer quantistici: Perché è necessaria?}

L'ipotesi di una minaccia quantistica emerge già nel ventesimo secolo, quando nel 1994 l'algoritmo di Shor dimostra che un 
computer quantistico sufficientemente potente potrebbe fattorizzare grandi numeri interi e calcolare logaritmi discreti 
in tempo polinomiale\footnote{P. Shor, "Algorithms for quantum computation: discrete logarithms and factoring", \textit{Proceedings 35th Annual Symposium on Foundations of Computer Science}, 1994, pp. 124-134}. Questo rende vulnerabili algoritmi come RSA, ECC e DSA, che costituiscono la base della sicurezza 
informatica moderna.

Per molti anni il problema è rimasto solo teorico, perché il calcolo quantistico non aveva applicazioni pratiche. 
Lo scenario è cambiato con i recenti progressi tecnologici e lo sviluppo dei primi prototipi avanzati da parte di leader industriali come Google e Microsoft, 
che hanno riportato risultati significativi con i loro progetti: Willow\footnote{Google Quantum AI, "Willow: A quantum computing milestone", Dicembre 2024. Disponibile su: \href{https://blog.google/innovation-and-ai/technology/research/google-willow-quantum-chip/}{blog.google}} di Google e il processore Maiorana 1\footnote{Microsoft Quantum, "Maiorana 1: The first milestone on the path to a quantum supercomputer", Ottobre 2024. Disponibile su: \href{https://news.microsoft.com/source/features/innovation/microsofts-majorana-1-chip-carves-new-path-for-quantum-computing/}{www.microsoft.com}} di Microsoft. 
Questi progetti hanno quindi portato alla luce dei veri calcolatori quantistici funzionanti e nonostante il limitato numero di qbit 
stabili sia insufficiente per applicazioni pratiche su larga scala, questo segna una svolta nel settore.

Sebbene le macchine quantistiche siano ancora in fase sperimentale, diversi scienziati ritengono che la loro costruzione 
su larga scala sia ormai una sfida principalmente ingegneristica, e alcuni prevedono la loro maturazione entro i prossimi vent'anni. 

Considerando che l'attuale infrastruttura crittografica ha richiesto quasi due decenni per essere implementata, risulta necessario 
iniziare da subito la transizione verso sistemi progettati per resistere al calcolo quantistico\footnote{D. J. Bernstein, "Introduction to post-quantum cryptography", \textit{Post-Quantum Cryptography}, Springer, 2009, pp. 1-14}.

\subsection{Obiettivi della crittografia post-quantistica}

L'obiettivo della crittografia post-quantistica è quindi sviluppare algoritmi crittografici 
sicuri sia contro i computer quantistici che classici, garantendo così un futuro sicuro 
anche in un'era dominata dai computer quantistici.

La crittografia post-quantistica non si limita a sostituire gli algoritmi vulnerabili, 
ma mira a costruire un'infrastruttura di sicurezza robusta e duratura, 
capace di adattarsi alle sfide tecnologiche future mantenendo la compatibilità con 
i protocolli e le reti esistenti\footnote{NIST, "Post-Quantum Cryptography Standardization", \url{https://csrc.nist.gov/projects/post-quantum-cryptography}}.

Lo scopo della relazione invece è quindi quello di fornire una panoramica completa, introducendo in 
primo luogo i fondamenti della crittografia classica, per capire dove risiedono le vulnerabilità che 
i computer quantistici sono in  grado di sfruttare. 
Una volta capiti tali principi, procederemo ad analizzare Shor, il suo impatto su tali algoritmi ed
infine le soluzioni proposte dalla crittografia post-quantistica.

\newpage

\section{Fondamenti della crittografia classica}

Come anticipato, per comprendere le sfide poste dai computer quantistici alla crittografia moderna, è fondamentale 
conoscerne i principi di base dietro i principali algoritmi crittografici attualmente in uso, in particolar modo 
ci concentreremo sui protocolli a chiave pubblica. 

\subsection{Crittografia a chiave pubblica: RSA, ECC}

La crittografia a chiave pubblica, introdotta nel 1976 da Diffie, Hellman e Merkle\footnote{W. Diffie, M. Hellman, "New directions in cryptography", \textit{IEEE Transactions on Information Theory}, vol. 22, no. 6, 1976, pp. 644-654}, costituisce 
una svolta fondamentale nel panorama della sicurezza informatica moderna. A differenza dei sistemi 
simmetrici, che vincolano mittente e destinatario alla condivisione di un unico segreto, i protocolli 
asimmetrici impiegano una coppia di chiavi: una pubblica $k_{\text{pub}}$, liberamente distribuibile, 
e una privata $k_{\text{prv}}$, mantenuta segreta dal proprietario. 
La sicurezza di questo sistema si basa sulla difficoltà di risalire alla chiave privata a partire 
da quella pubblica. Le funzioni di cifratura $C$ e decifratura $D$ sono note a tutti, e 
per ogni messaggio $m$ deve valere:
\[
D(C(m;k_{\text{pub}});k_{\text{prv}})=m.
\]

Il funzionamento di questo sistema si basa sulle funzioni one-way trapdoor: operazioni matematiche 
semplici da eseguire in una direzione, ma computazionalmente intrattabili da invertire senza 
la conoscenza di una informazione specifica (la "trappola").

La teoria dei numeri e l'algebra modulare forniscono il substrato matematico necessario per 
generare tali funzioni; a seconda del problema matematico sottostante, si distinguono i 
vari algoritmi di crittografia asimmetrica oggi in uso.

\paragraph{Richiami di algebra modulare}

L'aritmetica modulare è un sistema in cui i numeri si riavvolgono entro un intervallo fissato da un modulo $n$. 
Quando un valore supera (o scende sotto) questo intervallo, viene riportato all'interno prendendo 
il resto della divisione per $n$.

Un esempio quotidiano è l'orologio: in un sistema a 12 ore il modulo è $12$. Se sono le
$10$ e aggiungo $4$ ore, il risultato non è $14$, ma $2$, perché:
\[
14 \equiv 2 \pmod{12}.
\]

Per calcolare $c = a \bmod b$ si considera il resto della divisione intera tra $a$ e $b$,
ottenendo un valore sempre compreso tra $0$ e $b-1$, esempio: $6 \bmod 4 = 2$.

\paragraph{Problemi difficili}
\begin{itemize}
    \item \textbf{Fattorizzazione:} dati $p,q$ è facile calcolare $n=pq$; dato $n$ è difficile trovare $p$ e $q$.
    \item \textbf{Radice modulare:} dato $y=x^z \bmod s$ invertire la potenza è difficile senza conoscere $\varphi(s)$.
    \item \textbf{Logaritmo discreto:} data $y=x^z \bmod s$ trovare $z$ è computazionalmente difficile.
\end{itemize}

\subsubsection{RSA}

Il cifrario RSA, proposto da Rivest, Shamir e Adleman nel 1978\footnote{R. Rivest, A. Shamir, L. Adleman, "A method for obtaining digital signatures and public-key cryptosystems", \textit{Communications of the ACM}, vol. 21, no. 2, 1978, pp. 120-126}, è il sistema crittografico a 
chiave pubblica più diffuso e studiato. La sua sicurezza si fonda sulla difficoltà computazionale 
della fattorizzazione di numeri interi molto grandi\footnote{Materiale didattico del corso di Crittografia, Università di Bologna, a.a. 2024/2025}.

\paragraph{Generazione delle chiavi} 

Ogni utente genera la propria coppia di chiavi attraverso i seguenti passaggi:

\begin{enumerate}
    \item Scelta di due numeri primi $p$ e $q$ molto grandi
    \item Calcolo di $n = pq$ e della funzione di Eulero $\phi(n) = (p-1)(q-1)$
    \item Scelta di un intero $e$ minore di $\phi(n)$ e coprimo con esso
    \item Calcolo dell'intero $d$, inverso moltiplicativo di $e$ modulo $\phi(n)$
\end{enumerate}

La chiave pubblica è la coppia $(e, n)$, mentre la chiave privata è $d$. 
La cifratura di un messaggio $m$ avviene calcolando $c = m^e \bmod n$, 
mentre la decifratura richiede il calcolo di $m = c^d \bmod n$.

La correttezza dell'algoritmo è garantita dal teorema di Eulero: 
poiché $ed \equiv 1 \pmod{\phi(n)}$, si ha $ed = 1 + k\phi(n)$ per qualche intero $k$, e quindi:
$$m^{ed} \bmod n = m^{1+k\phi(n)} \bmod n = m \cdot (m^{\phi(n)})^k \bmod n = m \bmod n$$

\paragraph{Sicurezza e dimensioni delle chiavi} 

La sicurezza di RSA dipende da l'impossibilità pratica di fattorizzare $n$ quando questo è sufficientemente grande. 
Conoscendo la fattorizzazione $n = pq$, un attaccante potrebbe infatti calcolare $\phi(n)$ e di conseguenza la chiave privata $d$.

Attualmente, le dimensioni delle chiavi considerate sicure sono di almeno 2048 bit, con raccomandazioni crescenti verso 4096 bit per applicazioni che richiedono sicurezza a lungo termine\footnote{NIST Special Publication 800-57 Part 1 Rev. 5, "Recommendation for Key Management", 2020}. Chiavi di 1024 bit sono considerate obsolete e vulnerabili ad attacchi con risorse computazionali moderne.

\subsubsection{Crittografia su Curve Ellittiche (ECC)}

La crittografia su curve ellittiche, sviluppata indipendentemente da Neal Koblitz e Victor Miller nel 1985\footnote{N. Koblitz, "Elliptic curve cryptosystems", \textit{Mathematics of Computation}, vol. 48, no. 177, 1987, pp. 203-209; V. Miller, "Use of elliptic curves in cryptography", \textit{CRYPTO}, 1985, pp. 417-426}, offre un'alternativa matematicamente elegante e computazionalmente efficiente a RSA.

\paragraph{Fondamenti matematici} Una curva ellittica su un campo finito $\mathbb{Z}_p$ (con $p$ primo e $p > 3$) è definita dall'equazione di Weierstrass in forma normale:
$$y^2 = x^3 + ax + b$$
dove $a, b \in \mathbb{Z}_p$ soddisfano la condizione $4a^3 + 27b^2 \bmod p \neq 0$, che garantisce l'assenza di punti singolari sulla curva\footnote{Materiale didattico del corso di Crittografia, Università di Bologna, a.a. 2024/2025}.

L'insieme dei punti $(x, y)$ che soddisfano questa equazione, insieme al punto all'infinito $\mathcal{O}$, forma un gruppo abeliano additivo. È possibile definire un'operazione di addizione tra punti della curva tale che, dati due punti $P$ e $Q$, la loro somma $P + Q$ sia ancora un punto della curva.

Per punti distinti $P = (x_P, y_P)$ e $Q = (x_Q, y_Q)$, con $P \neq -Q$, si ha:
$$\lambda = \frac{y_Q - y_P}{x_Q - x_P}, \quad x_S = \lambda^2 - x_P - x_Q, \quad y_S = -y_P + \lambda(x_P - x_S)$$

dove $S = P + Q = (x_S, y_S)$. Nel caso di raddoppio di un punto ($P = Q$), il coefficiente angolare diventa $\lambda = \frac{3x_P^2 + a}{2y_P}$.

\paragraph{Il problema del logaritmo discreto} La sicurezza di ECC si basa sulla difficoltà del problema del logaritmo discreto su curve ellittiche (ECDLP): dati due punti $P$ e $Q$ sulla curva, trovare l'intero $k$ tale che $Q = kP$, dove $kP$ denota l'addizione di $P$ con se stesso $k$ volte.

La moltiplicazione scalare $Q = kP$ è computazionalmente efficiente (tempo polinomiale), mentre il problema inverso è considerato intrattabile: tutti gli algoritmi classici noti hanno complessità esponenziale nella dimensione della chiave.

\paragraph{Vantaggi rispetto a RSA} ECC offre lo stesso livello di sicurezza di RSA con chiavi significativamente più corte. Una chiave ECC di 256 bit fornisce una sicurezza paragonabile a una chiave RSA di 3072 bit\footnote{NIST Special Publication 800-57 Part 1 Rev. 5, "Recommendation for Key Management", 2020}. Questo si traduce in:
\begin{itemize}
    \item Minore occupazione di memoria e larghezza di banda
    \item Operazioni crittografiche più veloci
    \item Minore consumo energetico, cruciale per dispositivi mobili e IoT
\end{itemize}

\subsubsection{Sicurezza classica}

Entrambi gli algoritmi sono considerati sicuri nell'ambito del calcolo classico per dimensioni di chiave appropriate. La loro robustezza deriva dalla complessità computazionale dei problemi matematici sottostanti:

\begin{itemize}
    \item \textbf{Fattorizzazione per RSA}: il miglior algoritmo classico noto è il General Number Field Sieve (GNFS), con complessità sub-esponenziale $O(e^{(64/9)^{1/3}(\ln n)^{1/3}(\ln \ln n)^{2/3}})$\footnote{A. K. Lenstra, H. W. Lenstra Jr., "The development of the number field sieve", \textit{Lecture Notes in Mathematics}, vol. 1554, Springer, 1993}
    \item \textbf{ECDLP per ECC}: gli algoritmi più efficienti, come il metodo rho di Pollard, hanno complessità completamente esponenziale $O(\sqrt{n})$, dove $n$ è l'ordine del gruppo\footnote{J. M. Pollard, "Monte Carlo methods for index computation (mod p)", \textit{Mathematics of Computation}, vol. 32, no. 143, 1978, pp. 918-924}
\end{itemize}

Questa differenza nella complessità degli attacchi spiega perché ECC richiede chiavi più corte per garantire lo stesso livello di sicurezza.

RSA e ECC costituiscono oggi la base dell'infrastruttura di sicurezza digitale globale, utilizzati in TLS/SSL per la sicurezza web, in SSH per l'accesso remoto sicuro, nella firma digitale di documenti e software, e in numerose altre applicazioni critiche.

\subsection{Limiti rispetto ai computer quantistici}

Avendo introdotto i fondamenti della crittografia classica possiamo provare ora ad analizzare
le vulnerabilità di questi algoritmi in particolar modo rispetto al calcolo quantistico. Infatti nei prossimi capitoli capiremo quali sono
i vantaggi che i computer quantistici offrono rispetto a quelli classici e come questi
possono compromettere la sicurezza degli algoritmi classici. in particolare esamineremo l'algoritmo 
di Shor e il suo impatto su RSA.
\newpage

\section{Computazione quantistica e impatto sulla crittografia classica}

Entriamo ora nel vivo della relazione, sviscerare i segreti dietro l'algoritmo di Shor per capire in che modo rompere il protocllo RSA appena descritto.
Per farlo avremo prima bisogno di introdurre alcuni concetti di base della computazione quantistica che shor utilizza per ottenere i suoi risultati. 
Una volta compresi questi concetti potremo procedere alla spiegazione dell'algoritmo vero e proprio.

\input{capitolo3}
\newpage

\section{Crittografia post quantistica}

La crittografia post-quantistica\footnote{\href{https://en.wikipedia.org/wiki/Post-quantum_cryptography}{Wikipedia: Post-quantum cryptography}}, anche nota come crittografia quantum-safe o quantum-resistant, è quell'ambito della ricerca e dello sviluppo di algoritmi crittografici (solitamente a chiave pubblica) progettati per essere sicuri contro attacchi crittanalitici effettuati da computer quantistici.
Ecco i pilastri fondamentali che compongono questa definizione:

\begin{enumerate}
    \item Indipendenza dall'hardware quantistico. A differenza della "crittografia quantistica"\footnote{\href{https://preprints.org/manuscript/202508.0555/v1}{Quantum Computing and Cryptography}} (che sfrutta i principi della fisica quantistica per proteggere le comunicazioni, come la distribuzione quantistica delle chiavi), la crittografia post-quantistica si basa su problemi matematici eseguiti su computer classici, ma strutturati in modo da essere resistenti anche ai futuri computer quantistici.
    
    \item Superamento della vulnerabilità agli algoritmi quantistici
    
    La crittografia post-quantistica deve essere immune alle due minacce principali rappresentate dai computer quantistici:
    \begin{itemize}
        \item Algoritmo di Shor: di cui abbiamo ampiamente discusso nel capitolo precedente.
        \item Algoritmo di Grover: in grado di fornire un'accelerazione quadratica per le ricerche brute-force non strutturate. Per contrastare Grover, la PQC simmetrica richiede semplicemente il raddoppio della lunghezza delle chiavi (ad esempio, passare da AES-128 a AES-256) per mantenere lo stesso livello di sicurezza.
    \end{itemize}

    \item Fondazione su nuovi problemi matematici:
    La PQC si basa su problemi matematici che, allo stato attuale della ricerca, non presentano vulnerabilità esponenziali quantistiche. Nel prossimo capitolo: \hyperref[cap:Algoritmi post-quantistici]{"Algoritmi post-quantistici"} esamineremo nel dettaglio le principali famiglie di problemi matematici su cui si basano gli algoritmi post-quantistici.

    \item "Forward Secrecy"
    Una definizione completa di PQC include la necessità di proteggere i dati non solo in futuro, ma anche oggi. 
    
    Il modello di minaccia "Harvest Now, Decrypt Later" (raccogli ora, decifra dopo) suggerisce che attori malintenzionati possano archiviare dati criptati oggi per decifrarli quando saranno disponibili computer quantistici sufficientemente potenti. 
    
    Per questo motivo è considerata una priorità di sicurezza nazionale e infrastrutturale immediatarisulta e non così lontana. Queste motivazioni infatti stanno guidando la comunità scentifica a standardizzare quanto prima possibile questi algoritmi in modo da iniziare una migrazione verso questi protocolli già oggi.
\end{enumerate}

\subsection{Requisiti e obiettivi}
\paragraph{Requisiti pratici e tempistiche}

Sebbene la minaccia sia teoricamente dimostrata, la realizzazione pratica di computer quantistici capaci di violare RSA ed ECC richiede risorse considerevoli. Secondo stime del NIST, per compromettere una chiave RSA-2048 sarebbero necessari diversi milioni di qubit logici affidabili, mentre le implementazioni attuali (2024) operano con centinaia di qubit fisici caratterizzati da elevati tassi di errore.

La transizione da qubit fisici a qubit logici richiede tecniche di correzione degli errori quantistici che impongono un overhead significativo: potrebbero essere necessari da centinaia a migliaia di qubit fisici per realizzare un singolo qubit logico stabile.

\subsection{Ruolo del Nist e processo di standardizzazione}
\paragraph{La risposta: crittografia post-quantistica}

Di fronte a questa minaccia emergente, il National Institute of Standards and Technology (NIST) ha avviato nel 2016 un processo di standardizzazione per identificare algoritmi crittografici resistenti agli attacchi quantistici. Nel luglio 2022, il NIST ha annunciato i primi algoritmi selezionati per la standardizzazione, basati su problemi matematici ritenuti difficili anche per computer quantistici, come i reticoli algebrici e i codici correttori di errori.

La migrazione verso la crittografia post-quantistica rappresenta una delle sfide più urgenti per la sicurezza informatica moderna, richiedendo un'attenta pianificazione per sostituire l'infrastruttura crittografica esistente mantenendo retrocompatibilità e garantendo una transizione graduale e sicura.

\newpage

\section{Algoritmi post-quantistici} \label{cap:Algoritmi post-quantistici}

\input{capitolo5}
\newpage

\section{Considerazioni finali}

\subsection{Stato attuale della tecnologia dei computer quantistici}

Un computer quantistico reale è un sistema fisico composto da qubit che devono mantenere le loro proprietà quantistiche per tutta la durata del calcolo. Le tecnologie attualmente più diffuse si basano su qubit superconduttori, che operano a temperature estremamente basse, prossime allo zero assoluto, tipicamente dell'ordine di alcune decine di millikelvin, al fine di ridurre il rumore termico e preservare la coerenza quantistica.

Il raggiungimento di tali condizioni richiede l'utilizzo di refrigeratori a diluizione, dispositivi complessi e costosi che rappresentano un primo limite alla scalabilità dei sistemi. Anche minime interferenze ambientali possono causare la \emph{decoerenza}, ovvero la perdita delle proprietà quantistiche dei qubit, compromettendo la correttezza del calcolo.

Un'ulteriore difficoltà riguarda il controllo delle operazioni quantistiche. Le porte devono essere applicate con estrema precisione, poiché errori anche molto piccoli tendono ad accumularsi rapidamente con l'aumentare del numero di qubit e della profondità del circuito.

Per mitigare questo problema si ricorre a tecniche di \emph{correzione d'errore quantistica}. Tuttavia, gli schemi attualmente noti richiedono l'impiego di un numero elevato di qubit fisici per realizzare un singolo qubit logico affidabile, tipicamente dell'ordine di centinaia o migliaia.

A causa dei limiti tecnologici attuali, in particolare dei tempi di coerenza ridotti e dell'elevato tasso di errore, l'esecuzione di algoritmi quantistici complessi su larga scala, come quelli necessari per rompere RSA a 2048 bit, non è ancora praticabile.

Per queste ragioni si ritiene che saranno necessari ancora diversi anni, se non decenni, prima che computer quantistici in grado di compromettere concretamente i sistemi crittografici attuali diventino disponibili. Nonostante ciò, i progressi tecnologici e gli investimenti in corso rendono questa prospettiva rilevante dal punto di vista della sicurezza a lungo termine.

\subsection{Stato attuale dei protocolli post-quantistici}

\paragraph{Considerazioni sulla migrazione}
Per mitigare i rischi, molte aziende (come Apple con PQ3 o Google) stanno adottando un approccio di crittografia ibrida, combinando un algoritmo classico con uno post-quantistico per garantire sicurezza anche nel caso in cui uno dei due si rivelasse vulnerabile in futuro.
\newpage

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}