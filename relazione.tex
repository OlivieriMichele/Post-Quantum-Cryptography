\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{braket}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}

\title{Crittografia Post-Quantum}
\author{Olivieri Michele}
\date{\today}

\begin{document}

\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduzione}

\subsection{Contesto e motivazioni} 

Per comprendere l'importanza della crittografia post-quantistica, è fondamentale analizzare 
il contesto in cui essa si inserisce e le motivazioni che ne hanno guidato lo sviluppo.

La crittografia classica, come visto a lezione, pone le sue fondamenta su problemi computazionalmente difficili 
per i quali non esistono algoritmi efficienti in grado di risolverli in tempi polinomiali.

Tuttavia, l'emergere dei computer quantistici ha introdotto una nuova dimensione nel panorama della sicurezza informatica.
Questi dispositivi sfruttando i principi della meccanica quantistica sono in grado di eseguire calcoli in modo radicalmente diverso 
rispetto ai computer classici, rendendoli potenzialmente capaci di risolvere in tempi polinomiali quei problemi matematici 
che risultano intrattabili per le macchine convenzionali.

\subsection[Minaccia dei computer quantistici]{Minaccia dei computer quantistici: Perché è necessaria?}

L’ipotesi di una minaccia quantistica emerge già nel ventesimo secolo, quando nel 1994 l’algoritmo di Shor dimostra che un 
computer quantistico sufficientemente potente potrebbe fattorizzare grandi numeri interi e calcolare logaritmi discreti 
in tempo polinomiale. Questo rende vulnerabili algoritmi come RSA, ECC e DSA, che costituiscono la base della sicurezza 
informatica moderna.

Per molti anni il problema è rimasto solo teorico, perché il calcolo quantistico non aveva applicazioni pratiche. 
Lo scenario è cambiato con i recenti progressi nel settore e con lo sviluppo dei primi prototipi di calcolatori quantistici 
da parte di aziende come Google e Microsoft, che hanno riportato risultati significativi con i loro progetti: Myorana 1 e Willow. 
Questi progetti hanno quindi portato alla luce dei veri calcolatori quantistici funzionanti e nonostante il limitato numero di qbit 
stabili sia insufficiente per applicazioni pratiche su larga scala, questo segna una svolta nel settore.

Sebbene le macchine quantistiche siano ancora in fase sperimentale, diversi scienziati ritengono che la loro costruzione 
su larga scala sia ormai una sfida principalmente ingegneristica, e alcuni prevedono la loro maturazione entro i prossimi vent’anni. 

Considerando che l’attuale infrastruttura crittografica ha richiesto quasi due decenni per essere implementata, risulta necessario 
iniziare da subito la transizione verso sistemi progettati per resistere al calcolo quantistico.

\subsection{Obiettivi della crittografia post-quantistica}

L'obiettivo della crittografia post-quantistica è quindi sviluppare algoritmi crittografici 
sicuri sia contro i computer quantistici che classici, garantendo così un futuro sicuro 
anche in un'era dominata dai computer quantistici.

La crittografia post-quantistica non si limita a sostituire gli algoritmi vulnerabili, 
ma mira a costruire un'infrastruttura di sicurezza robusta e duratura, 
capace di adattarsi alle sfide tecnologiche future mantenendo la compatibilità con 
i protocolli e le reti esistenti.

\newpage

\section{Fondamenti della crittografia classica}

Per comprendere le sfide poste dai computer quantistici alla crittografia moderna, è fondamentale 
conoscerne i principi di base dietro i principali algoritmi crittografici attualmente in uso.
Una volta capiti tali principi, procederemo ad analizzare Shor, il suo impatto sugli algoritmi ed
infine le soluzioni proposte dalla crittografia post-quantistica.

\subsection{Crittografia a chiave pubblica: RSA, ECC}

La crittografia a chiave pubblica, introdotta nel 1976 da Diffie, Hellman e Merkle, costituisce 
una svolta fondamentale nel panorama della sicurezza informatica moderna. A differenza dei sistemi 
simmetrici, che vincolano mittente e destinatario alla condivisione di un unico segreto, i protocolli 
asimmetrici impiegano una coppia di chiavi: una pubblica $k_{\text{pub}}$, liberamente distribuibile, 
e una privata $k_{\text{prv}}$, mantenuta segreta dal proprietario. 
La sicurezza di questo sistema si basa sulla difficoltà di risalire alla chiave privata a partire 
da quella pubblica. Le funzioni di cifratura $C$ e decifratura $D$ sono note a tutti, e 
per ogni messaggio $m$ deve valere:
\[
D(C(m;k_{\text{pub}});k_{\text{prv}})=m.
\]

Il funzionamento di questo sistema si basa sulle funzioni one-way trapdoor: operazioni matematiche 
semplici da eseguire in una direzione, ma computazionalmente intrattabili da invertire senza 
la conoscenza di un'informazione specifica (la "trappola").

La teoria dei numeri e l'algebra modulare forniscono il substrato matematico necessario per 
generare tali funzioni; a seconda del problema matematico sottostante, si distinguono i 
vari algoritmi di crittografia asimmetrica oggi in uso.

\paragraph{Richiami di algebra modulare}

L'aritmetica modulare è un sistema in cui i numeri si riavvolgono entro un intervallo fissato da un modulo $n$. 
Quando un valore supera (o scende sotto) questo intervallo, viene riportato all’interno prendendo 
il resto della divisione per $n$.

Un esempio quotidiano è l’orologio: in un sistema a 12 ore il modulo è $12$. Se sono le
$10$ e aggiungo $4$ ore, il risultato non è $14$, ma $2$, perché:
\[
14 \equiv 2 \pmod{12}.
\]

Per calcolare $c = a \bmod b$ si considera il resto della divisione intera tra $a$ e $b$,
ottenendo un valore sempre compreso tra $0$ e $b-1$, esempio: $6 \bmod 4 = 2$.

\paragraph{Problemi difficili}
\begin{itemize}
    \item \textbf{Fattorizzazione:} dati $p,q$ è facile calcolare $n=pq$; dato $n$ è difficile trovare $p$ e $q$.
    \item \textbf{Radice modulare:} dato $y=x^z \bmod s$ invertire la potenza è difficile senza conoscere $\varphi(s)$.
    \item \textbf{Logaritmo discreto:} data $y=x^z \bmod s$ trovare $z$ è computazionalmente difficile.
\end{itemize}

\subsubsection{RSA}

Il cifrario RSA, proposto da Rivest, Shamir e Adleman nel 1978, è il sistema crittografico a 
chiave pubblica più diffuso e studiato. La sua sicurezza si fonda sulla difficoltà computazionale 
della fattorizzazione di numeri interi molto grandi.

\paragraph{Generazione delle chiavi} 

Ogni utente genera la propria coppia di chiavi attraverso i seguenti passaggi:

\begin{enumerate}
    \item Scelta di due numeri primi $p$ e $q$ molto grandi
    \item Calcolo di $n = pq$ e della funzione di Eulero $\phi(n) = (p-1)(q-1)$
    \item Scelta di un intero $e$ minore di $\phi(n)$ e coprimo con esso
    \item Calcolo dell'intero $d$, inverso moltiplicativo di $e$ modulo $\phi(n)$
\end{enumerate}

La chiave pubblica è la coppia $(e, n)$, mentre la chiave privata è $d$. 
La cifratura di un messaggio $m$ avviene calcolando $c = m^e \bmod n$, 
mentre la decifratura richiede il calcolo di $m = c^d \bmod n$.

La correttezza dell'algoritmo è garantita dal teorema di Eulero: 
poiché $ed \equiv 1 \pmod{\phi(n)}$, si ha $ed = 1 + k\phi(n)$ per qualche intero $k$, e quindi:
$$m^{ed} \bmod n = m^{1+k\phi(n)} \bmod n = m \cdot (m^{\phi(n)})^k \bmod n = m \bmod n$$

\paragraph{Sicurezza e dimensioni delle chiavi} 

La sicurezza di RSA dipende dall'impossibilità pratica di fattorizzare $n$ quando questo è sufficientemente grande. 
Conoscendo la fattorizzazione $n = pq$, un attaccante potrebbe infatti calcolare $\phi(n)$ e di conseguenza la chiave privata $d$.

Attualmente, le dimensioni delle chiavi considerate sicure sono di almeno 2048 bit, con raccomandazioni crescenti verso 4096 bit per applicazioni che richiedono sicurezza a lungo termine. Chiavi di 1024 bit sono considerate obsolete e vulnerabili ad attacchi con risorse computazionali moderne.

\subsubsection{Crittografia su Curve Ellittiche (ECC)}

La crittografia su curve ellittiche, sviluppata indipendentemente da Neal Koblitz e Victor Miller nel 1985, offre un'alternativa matematicamente elegante e computazionalmente efficiente a RSA.

\paragraph{Fondamenti matematici} Una curva ellittica su un campo finito $\mathbb{Z}_p$ (con $p$ primo e $p > 3$) è definita dall'equazione di Weierstrass in forma normale:
$$y^2 = x^3 + ax + b$$
dove $a, b \in \mathbb{Z}_p$ soddisfano la condizione $4a^3 + 27b^2 \bmod p \neq 0$, che garantisce l'assenza di punti singolari sulla curva.

L'insieme dei punti $(x, y)$ che soddisfano questa equazione, insieme al punto all'infinito $\mathcal{O}$, forma un gruppo abeliano additivo. È possibile definire un'operazione di addizione tra punti della curva tale che, dati due punti $P$ e $Q$, la loro somma $P + Q$ sia ancora un punto della curva.

Per punti distinti $P = (x_P, y_P)$ e $Q = (x_Q, y_Q)$, con $P \neq -Q$, si ha:
$$\lambda = \frac{y_Q - y_P}{x_Q - x_P}, \quad x_S = \lambda^2 - x_P - x_Q, \quad y_S = -y_P + \lambda(x_P - x_S)$$

dove $S = P + Q = (x_S, y_S)$. Nel caso di raddoppio di un punto ($P = Q$), il coefficiente angolare diventa $\lambda = \frac{3x_P^2 + a}{2y_P}$.

\paragraph{Il problema del logaritmo discreto} La sicurezza di ECC si basa sulla difficoltà del problema del logaritmo discreto su curve ellittiche (ECDLP): dati due punti $P$ e $Q$ sulla curva, trovare l'intero $k$ tale che $Q = kP$, dove $kP$ denota l'addizione di $P$ con se stesso $k$ volte.

La moltiplicazione scalare $Q = kP$ è computazionalmente efficiente (tempo polinomiale), mentre il problema inverso è considerato intrattabile: tutti gli algoritmi classici noti hanno complessità esponenziale nella dimensione della chiave.

\paragraph{Vantaggi rispetto a RSA} ECC offre lo stesso livello di sicurezza di RSA con chiavi significativamente più corte. Una chiave ECC di 256 bit fornisce una sicurezza paragonabile a una chiave RSA di 3072 bit. Questo si traduce in:
\begin{itemize}
    \item Minore occupazione di memoria e larghezza di banda
    \item Operazioni crittografiche più veloci
    \item Minore consumo energetico, cruciale per dispositivi mobili e IoT
\end{itemize}

\subsubsection{Sicurezza classica}

Entrambi gli algoritmi sono considerati sicuri nell'ambito del calcolo classico per dimensioni di chiave appropriate. La loro robustezza deriva dalla complessità computazionale dei problemi matematici sottostanti:

\begin{itemize}
    \item \textbf{Fattorizzazione per RSA}: il miglior algoritmo classico noto è il General Number Field Sieve (GNFS), con complessità sub-esponenziale $O(e^{(64/9)^{1/3}(\ln n)^{1/3}(\ln \ln n)^{2/3}})$
    \item \textbf{ECDLP per ECC}: gli algoritmi più efficienti, come il metodo rho di Pollard, hanno complessità completamente esponenziale $O(\sqrt{n})$, dove $n$ è l'ordine del gruppo
\end{itemize}

Questa differenza nella complessità degli attacchi spiega perché ECC richiede chiavi più corte per garantire lo stesso livello di sicurezza.

RSA e ECC costituiscono oggi la base dell'infrastruttura di sicurezza digitale globale, utilizzati in TLS/SSL per la sicurezza web, in SSH per l'accesso remoto sicuro, nella firma digitale di documenti e software, e in numerose altre applicazioni critiche.

\subsection{Limiti rispetto ai computer quantistici}

Avendo introdotto i fondamenti della crittografia classica possiamo provare ora ad analizzare
le vulnerabilità di questi algoritmi in particolar modo rispetto al calcolo quantistico. Infatti nei prossimi capitoli capiremo quali sono
i vantaggi che i computer quantistici offrono rispetto a quelli classici e come questi
possono compromettere la sicurezza degli algoritmi classici. in particolare esamineremo l'algoritmo 
di Shor e il suo impatto su RSA.
\newpage

\section{Computazione quantistica e impatto sulla crittografia classica}

Entriamo ora nel vivo della relazione, sviscerare i segreti dietro l'algoritmo di Shor per capire in che modo rompere il protocllo RSA appena descritto.
Per farlo avremo prima bisogno di introdurre alcuni concetti di base della computazione quantistica che shor utilizza per ottenere i suoi risultati. 
Una volta compresi questi concetti potremo procedere alla spiegazione dell'algoritmo vero e proprio.

\input{capitolo3}

\section{Crittografia post quantistica}

\subsection{Definizione, requisiti e obiettivi}
\paragraph{Requisiti pratici e tempistiche}

Sebbene la minaccia sia teoricamente dimostrata, la realizzazione pratica di computer quantistici capaci di violare RSA ed ECC richiede risorse considerevoli. Secondo stime del NIST, per compromettere una chiave RSA-2048 sarebbero necessari diversi milioni di qubit logici affidabili, mentre le implementazioni attuali (2024) operano con centinaia di qubit fisici caratterizzati da elevati tassi di errore.

La transizione da qubit fisici a qubit logici richiede tecniche di correzione degli errori quantistici che impongono un overhead significativo: potrebbero essere necessari da centinaia a migliaia di qubit fisici per realizzare un singolo qubit logico stabile.

Nonostante queste difficoltà tecnologiche, il principio "harvest now, decrypt later" rappresenta una preoccupazione concreta: un attaccante potrebbe intercettare e archiviare oggi comunicazioni cifrate con RSA o ECC, per decifrarle in futuro quando disporrà di computer quantistici sufficientemente potenti. Questa considerazione è particolarmente rilevante per dati che richiedono riservatezza a lungo termine, come informazioni mediche, segreti industriali o comunicazioni governative.

\subsection{Ruolo del Nist e processo di standardizzazione}
\paragraph{La risposta: crittografia post-quantistica}

Di fronte a questa minaccia emergente, il National Institute of Standards and Technology (NIST) ha avviato nel 2016 un processo di standardizzazione per identificare algoritmi crittografici resistenti agli attacchi quantistici. Nel luglio 2022, il NIST ha annunciato i primi algoritmi selezionati per la standardizzazione, basati su problemi matematici ritenuti difficili anche per computer quantistici, come i reticoli algebrici e i codici correttori di errori.

La migrazione verso la crittografia post-quantistica rappresenta una delle sfide più urgenti per la sicurezza informatica moderna, richiedendo un'attenta pianificazione per sostituire l'infrastruttura crittografica esistente mantenendo retrocompatibilità e garantendo una transizione graduale e sicura.

\newpage

\section{Panorama sugli algoritmi post-quantistici}

\section{Considerazioni finali}

\subsection{Stato attuale della tecnologia dei computer quantistici}

Un computer quantistico reale è un sistema fisico composto da qubit che devono mantenere le loro proprietà quantistiche per tutta la durata del calcolo. Le tecnologie attualmente più diffuse si basano su qubit superconduttori, che operano a temperature estremamente basse, prossime allo zero assoluto, tipicamente dell'ordine di alcune decine di millikelvin, al fine di ridurre il rumore termico e preservare la coerenza quantistica.

Il raggiungimento di tali condizioni richiede l'utilizzo di refrigeratori a diluizione, dispositivi complessi e costosi che rappresentano un primo limite alla scalabilità dei sistemi. Anche minime interferenze ambientali possono causare la \emph{decoerenza}, ovvero la perdita delle proprietà quantistiche dei qubit, compromettendo la correttezza del calcolo.

Un'ulteriore difficoltà riguarda il controllo delle operazioni quantistiche. Le porte devono essere applicate con estrema precisione, poiché errori anche molto piccoli tendono ad accumularsi rapidamente con l'aumentare del numero di qubit e della profondità del circuito.

Per mitigare questo problema si ricorre a tecniche di \emph{correzione d'errore quantistica}. Tuttavia, gli schemi attualmente noti richiedono l'impiego di un numero elevato di qubit fisici per realizzare un singolo qubit logico affidabile, tipicamente dell'ordine di centinaia o migliaia.

A causa dei limiti tecnologici attuali, in particolare dei tempi di coerenza ridotti e dell'elevato tasso di errore, l'esecuzione di algoritmi quantistici complessi su larga scala, come quelli necessari per rompere RSA a 2048 bit, non è ancora praticabile.

Per queste ragioni si ritiene che saranno necessari ancora diversi anni, se non decenni, prima che computer quantistici in grado di compromettere concretamente i sistemi crittografici attuali diventino disponibili. Nonostante ciò, i progressi tecnologici e gli investimenti in corso rendono questa prospettiva rilevante dal punto di vista della sicurezza a lungo termine.

\subsection{Stato attuale dei protocolli post-quantistici}
\newpage

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}